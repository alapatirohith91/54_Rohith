

# ğŸš¨ Transaction Fraud Detection at Scale

---

## ğŸ¯ Problem Statement

Given millions of transaction records with **<1% fraud rate**, build a machine learning system that:

* Identifies high-risk fraudulent transactions
* Maximizes recall without overwhelming false alerts
* Produces a ranked **fraud risk score** per transaction

---

## ğŸ“Š Dataset

**PaySim â€“ Synthetic Financial Fraud Dataset**

* Source: Kaggle
* Link: [https://www.kaggle.com/datasets/ealaxi/paysim1](https://www.kaggle.com/datasets/ealaxi/paysim1)
* Records: ~6.3 million
* Fraud Rate: < 1%

PaySim simulates real mobile money behavior, making it ideal for testing **fraud detection pipelines under realistic conditions**.

---

## ğŸ§  End-to-End Solution Architecture

```
Raw Transactions
        â†“
Data Cleaning & Encoding
        â†“
Domain-Driven Feature Engineering
        â†“
Stratified Train-Test Split
        â†“
Imbalance Handling (Class Weights / SMOTE)
        â†“
Model Training (LightGBM)
        â†“
Threshold Optimization
        â†“
Precision@K / Recall@K Evaluation
        â†“
Fraud Risk Scoring (CSV Output)
```

---

## ğŸ”¬ Feature Engineering (Key Innovation)

Instead of relying only on raw fields, the model learns **fraud behavior patterns** through:

* Balance change before vs after transaction
* Transaction amount to balance ratio
* Zero-balance anomaly indicators
* Behavioral inconsistencies across transaction types

These features significantly improve the modelâ€™s ability to detect **subtle fraud signals**.

---

## âš–ï¸ Handling Severe Class Imbalance

Three strategies were evaluated:

| Technique               | Purpose                           |
| ----------------------- | --------------------------------- |
| Baseline (No balancing) | Reference comparison              |
| Class Weighting         | Penalizes fraud misclassification |
| SMOTE                   | Synthetic fraud sample generation |

ğŸ‘‰ **Class weighting with LightGBM** provided the best balance between recall and false positives.

---

## ğŸ¤– Models Implemented

* Logistic Regression (baseline)
* Random Forest
* **LightGBM (Final Model)**

### Why LightGBM?

* Optimized for large-scale tabular data
* Handles class imbalance natively
* Faster training and superior recall
* Widely adopted in real fraud detection systems

---

## ğŸ“ Evaluation Strategy (Business-Aligned)

Traditional accuracy is misleading for fraud problems.
This project evaluates models using:

* **Precision@K** â†’ Are the top K alerts actually fraud?
* **Recall@K** â†’ How many fraud cases are captured?
* ROC-AUC
* Confusion Matrix

Additionally, **decision thresholds were tuned**, reflecting real-world alerting systems.

---

## ğŸ“ˆ Key Results

* Substantial improvement in fraud recall over baseline
* High precision for top-ranked fraud alerts
* Reduced false positives while maximizing fraud capture
* Stable generalization on unseen data

---

## ğŸ“¤ Output: Fraud Risk Scoring

Final output is a **ranked fraud score CSV**:

```text
transaction_id, fraud_score, fraud_prediction
100231, 0.93, 1
100232, 0.08, 0
```

This format is ready for:

* Fraud alert systems
* Risk dashboards
* Automated decision pipelines

---

## ğŸ§° Tech Stack

* **Language:** Python
* **ML:** scikit-learn, LightGBM
* **Imbalance Handling:** imbalanced-learn
* **Data:** pandas, numpy
* **Visualization:** matplotlib
* **Experiment Tracking (Optional):** MLflow
* **Platform:** Jupyter Notebook

---

## â–¶ï¸ How to Run

```bash
pip install -r requirements.txt
jupyter notebook fraud_detection.ipynb
```

---

## ğŸš€ Future Extensions

* Ensemble stacking (LightGBM + ANN)
* Explainability using SHAP
* Real-time fraud detection API
* Adaptive thresholds based on transaction risk

---

## ğŸ Hackathon Impact Summary

âœ” Real-world fraud detection framing
âœ” Imbalanced ML best practices
âœ” Business-relevant metrics
âœ” Scalable and deployable pipeline
âœ” Clear, judge-friendly documentation
